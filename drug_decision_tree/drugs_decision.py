# -*- coding: utf-8 -*-
"""Drugs_Decision.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1GRv4ahnbG1-jV_DZLV3_sW2Nzsohy9tw

# Drug Decision Tree

With a background rooted in medicineâ€”particularly in predictive modeling for conditions like Acute Promyelocytic Leukemia (APL)â€”I've always been interested in how data can support treatment decisions. While my prior work focused on real-world oncology datasets, this project uses a public dataset from Kaggle (https://www.kaggle.com/datasets/pablomgomez21/drugs-a-b-c-x-y-for-decision-trees) as a proxy to demonstrate decision tree modeling for drug classification.

In this notebook, I build an interpretable classification model using decision trees with tuned hyperparameters. The objective is to predict appropriate drug treatment based on patient features such as age, blood pressure, cholesterol levels, and sodium-to-potassium ratios.

This project is intended to showcase my technical skills, not replicate clinical workflows. In a real-world healthcare application, my approach would adapt based on the problem context, data constraints, and domain expertise.

## Setting Data and Data Preparation

In this section, we load the drug treatment dataset and prepare it for modeling. The dataset includes patient attributes such as:

+ Age

+ Sex

+ Blood Pressure (BP)

+ Cholesterol

+ Sodium-to-Potassium Ratio

These features are used to classify which of five drugs (Drug A, B, C, X, or Y) a patient is most likely to be prescribed.

To ensure the model performs well, we:

+ Import the dataset using pandas

+ Encode categorical variables using LabelEncoder

+ Split the dataset into training and testing sets

+ Scale the features for better model performance and convergence

This preprocessing stage helps create a clean, normalized input spaceâ€”crucial for interpretable and accurate decision tree construction.
"""

import pandas as pd
drug = pd.read_csv('/content/drive/MyDrive/Colab/ABCD_Drugs/drug200.csv')
drug.head()

drug.info()
drug.isnull().sum()

cat_col = [col for col in drug.columns if drug[col].dtype == 'O']
drug_categorical = drug[cat_col]
drug_categorical.head()

from sklearn.preprocessing import LabelEncoder

Label_Encoded = LabelEncoder()

for col in cat_col:
    drug_categorical[col] = Label_Encoded.fit_transform(drug_categorical[col])

drug_categorical.head()

drug.drop(cat_col,axis=1,inplace=True)

drug_data_cleaned = pd.concat([drug,drug_categorical],axis=1)

drug_data_cleaned.tail()

drug_data_cleaned.info()

drug_data_cleaned['Drug'] = drug_data_cleaned['Drug'].astype('category')

"""## Establishing the Model

In this step, we construct our baseline decision tree classifier to predict drug type based on patient attributes.

- **Data Splitting:** We divide the cleaned dataset into training and testing sets using an 80/20 split. This allows us to train the model on one portion of the data and validate its performance on unseen examples.

- **Model Selection:** We use DecisionTreeClassifier from scikit-learn for its simplicity and interpretabilityâ€”ideal for showcasing rule-based decision logic, especially in medical or regulated settings.

- **Max Depth = 5:** The treeâ€™s depth controls its complexity. A depth of 5 strikes a balance:
  - Deep enough to learn meaningful patterns across multiple conditions (e.g., age, blood pressure, cholesterol).
  - Shallow enough to avoid **overfitting**, which can occur with deeper trees (e.g., depth 10).
  - More interpretable than a very shallow tree (e.g., depth 2), which may be too simple to capture real-world variability.

This baseline model serves as a starting point for future tuning and comparison with more complex models.

"""

from sklearn.model_selection import train_test_split

X = drug_data_cleaned.drop(columns = ['Drug'])
y = drug_data_cleaned['Drug']

X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.2)
X_train.shape, X_test.shape, y_train.shape, y_test.shape

from sklearn.tree import DecisionTreeClassifier
DT_default = DecisionTreeClassifier(max_depth=5)
model_DT = DT_default.fit(X_train,y_train)
model_DT

y_pred_test_default = model_DT.predict(X_test)

"""## Initial Model Evaluation

In this section, we assess the performance of our baseline decision tree model using standard evaluation metrics.

### What We're Doing:
- **Classification Report:** Outputs key performance metricsâ€”**precision**, **recall**, **F1-score**, and **support**â€”for each drug class. This gives insight into how well the model is predicting each category.
- **Confusion Matrix:** Shows how often the model is correctly vs. incorrectly predicting drug classes. Useful for spotting class-specific errors.
- **Accuracy Score:** Provides an overall percentage of correct predictions.
- **Visualization:** We plot the confusion matrix as a heatmap to visually interpret the model's strengths and weaknesses.

### Why This Matters:


These metrics give a first look at how well our model performs with the default settings and current hyperparameters (e.g., `max_depth=5`). While accuracy is important, reviewing precision and recall helps us understand trade-offs in false positives vs. false negativesâ€”especially critical in medical applications.

This step sets the benchmark for future tuning and model comparisons.

"""

from sklearn.metrics import classification_report
from sklearn.metrics import confusion_matrix
from sklearn.metrics import accuracy_score
from sklearn.metrics import confusion_matrix

import matplotlib.pyplot as plt

print(classification_report(y_test,y_pred_test_default))

print(f' Confusion_Matrix: \n {confusion_matrix(y_test,y_pred_test_default)}','\n')

print(f' Accuracy_Score:\n {accuracy_score(y_test,y_pred_test_default)}')

y_pred = model_DT.predict(X_test)
cm = confusion_matrix(y_test, y_pred)
plt.imshow(cm, cmap='rainbow')
plt.title('Confusion Matrix')
plt.colorbar()
plt.xlabel('Predicted')
plt.ylabel('True')
plt.show()

"""## Interpreting the Decision Tree Structure

In this section, we examine the **learned structure** of our decision tree model. This tree is built using a `max_depth=5`, which helps prevent overfitting by limiting how specific the tree can become to the training data.

### What the Tree Represents:
Each node in the tree represents a decision rule based on one of the features (e.g., age, blood pressure, cholesterol level). The tree splits the data based on these rules to classify patients into one of five drug categories.


### Why This Matters:
This tree shows **how the model is learning from the data** and **how it arrives at its final prediction**. Decision trees are highly interpretable, making them ideal for domains like healthcare, where understanding **why** a decision was made is just as important as the decision itself.

Each path from the root to a leaf node defines a set of rules for predicting a specific drug class. This transparency makes it easy to audit and improve the model, and ensures that decisions align with clinical logic.


"""

from sklearn.tree import plot_tree
from sklearn.tree import export_text

plt.figure(figsize=(250,100))
plot_tree(model_DT,filled=True)
plt.show()

text_representation = export_text(model_DT)
print(text_representation)

"""### Hyperparameter Tuning

Although the dataset used here is relatively small â€” and the performance differences between hyperparameter settings may be minimal â€” practicing robust model tuning is essential in real-world applications. In my professional work, particularly in clinical modeling and credit scoring, hyperparameter tuning is a vital step for ensuring model generalizability and stability.

To demonstrate this rigor, we'll explore **three common tuning approaches**:

1. **K-Fold Cross-Validation**  
   Used to evaluate model performance by rotating through training and validation splits. It gives a more stable estimate of model accuracy.

2. **Grid Search**  
   Exhaustively tests all combinations of specified hyperparameter values. While computationally expensive, it guarantees the discovery of the optimal parameter set within the grid.

3. **Random Search**  
   Samples a fixed number of parameter combinations from a defined range. It's often faster than Grid Search and works well when only a few hyperparameters significantly impact performance.

By incorporating these methods, we demonstrate not just our understanding of the mechanics of decision trees, but our commitment to robust and scalable modeling practices.

"""

from sklearn.model_selection import KFold
from sklearn.model_selection import GridSearchCV

n_folds = 10
parameters = {'max_depth':range(1,20)}

dtree = DecisionTreeClassifier(criterion='gini')

GScv = GridSearchCV(estimator=dtree, param_grid=parameters, scoring='accuracy',
                    cv=n_folds, return_train_score=True)

GScv.fit(X_train,y_train)

scores_GScv = GScv.cv_results_

scores_GScv_df = pd.DataFrame(scores_GScv)
scores_GScv_df.head()

scores_GScv_df_scores = scores_GScv_df[['params','mean_train_score','mean_test_score']]
scores_GScv_df_scores.head()

plt.figure(figsize=(20,10))

plt.plot(scores_GScv_df['mean_train_score'],label="training accuracy",marker='o',linestyle='dashed')
plt.plot(scores_GScv_df['mean_test_score'],label="test accuracy",marker='o',linestyle='dashed')

plt.legend(loc="upper left", prop={'size':10})
plt.xlabel("max_depth", size=10)
plt.ylabel("Accuracy", size=10)

plt.show()

n_folds = 10
parameters = {'min_samples_leaf':range(5,200,20)}
dtree = DecisionTreeClassifier(criterion='gini')

GScv = GridSearchCV(estimator=dtree,param_grid=parameters,
                    scoring='accuracy',cv=n_folds,return_train_score=True)

GScv.fit(X_train,y_train)

scores_GScv = GScv.cv_results_

scores_GScv_df = pd.DataFrame(scores_GScv)
scores_GScv_df.head()

plt.figure(figsize=(16,5))

plt.plot(scores_GScv_df['mean_train_score'],label="training accuracy",marker='o',linestyle='dashed')
plt.plot(scores_GScv_df['mean_test_score'],label="test accuracy",marker='o',linestyle='dashed')

plt.legend(loc="best", prop={'size':12}) # loc = best,upper right,upper left,lower left,lower right,right,center left,center right,lower center,upper center,center
plt.xlabel("min_samples_leaf", size=15)
plt.ylabel("Accuracy", size=15)
plt.xticks(range(0,10,1))

plt.show()

n_folds = 10
parameters = {"min_samples_split":range(5,200,20)}

dtree = DecisionTreeClassifier(criterion='gini')

GScv = GridSearchCV(dtree,parameters,cv=n_folds,scoring='accuracy',return_train_score=True)

GScv.fit(X_train,y_train)

scores_GScv = GScv.cv_results_

scores_GScv_df = pd.DataFrame(scores_GScv)
scores_GScv_df.head()

plt.figure(figsize=(16,5))

plt.plot(scores_GScv_df['mean_train_score'],label="training accuracy",marker='o',linestyle='dashed')
plt.plot(scores_GScv_df['mean_test_score'],label="test accuracy",marker='o',linestyle='dashed')

plt.legend(loc="best", prop={'size':12})
plt.xlabel("min_samples_split",size=15)
plt.ylabel("Accuracy",size=15)
plt.xticks(range(0,10,1))

plt.show()

n_folds = 10

param_grid = {
    'max_depth': range(5,15,5),
    'min_samples_leaf': range(50,150,50),
    'min_samples_split': range(50,150,50),
    'criterion': ["entropy","gini"]}

dtree = DecisionTreeClassifier()


grid_search = GridSearchCV(estimator=dtree,param_grid=param_grid,cv=n_folds,verbose=1)

grid_search.fit(X_train,y_train)

cv_results = grid_search.cv_results_

cv_results_df =  pd.DataFrame(cv_results)
cv_results_df.head()

print(f' Best Accuracy you can get:\n {grid_search.best_score_}\n','***'*15)

print(f' Best Hyperparameters Parameters & there Values: \n{grid_search.best_params_}')

dt_with_optimal_hyperparameters = DecisionTreeClassifier(criterion='entropy',max_depth=10,min_samples_leaf=50,
                                                         min_samples_split=50,random_state=108)


model_dt = dt_with_optimal_hyperparameters.fit(X_train,y_train)
model_dt

from sklearn import metrics

y_pred_test = model_dt.predict(X_test)
metrics.accuracy_score(y_test,y_pred_test)

fig = plt.figure(figsize=(100,30))
plot_tree(model_dt,filled=True,fontsize=20)
plt.show()

print(export_text(model_dt))

"""## Adjusting max_depth for Model Simplicity

In this step, we retrain the decision tree using more conservative settings to prioritize **simplicity** and **interpretability** over complexity.

We set:
- max_depth = 3 : Limits how deep the tree can grow, ensuring decisions are made with fewer splits and simpler logic paths.
- min_samples_leaf = 50 and min_samples_split = 50: Prevent the model from overfitting small sample groups, improving generalization.

While this doesnâ€™t guarantee the highest possible accuracy, it creates a more **stable and understandable** model â€” a crucial factor when making data-driven recommendations in sensitive fields like healthcare or finance.

We then reassess performance on the test set to ensure the model remains viable under these adjusted parameters.

"""

dt_with_max_depth_optimal_hyperparameters =  DecisionTreeClassifier(criterion='entropy',max_depth=3,min_samples_leaf=50,
                                                                    min_samples_split=50)
model_dt = dt_with_max_depth_optimal_hyperparameters.fit(X_train,y_train)

y_pred_test = model_dt.predict(X_test)
metrics.accuracy_score(y_test,y_pred_test)

plt.figure(figsize=(20,6))

plot_tree(model_dt,filled=True,fontsize=10)

plt.show()

print(export_text(model_dt))

print(metrics.classification_report(y_test,y_pred_test))

print(metrics.confusion_matrix(y_test,y_pred_test),'\n','***'*10)

import matplotlib.pyplot as plt
import seaborn as sns

confusion_mat = metrics.confusion_matrix(y_test, y_pred_test)

sns.heatmap(confusion_mat, annot=True, fmt='d')
plt.xlabel('Predicted')
plt.ylabel('True')
plt.title('Confusion Matrix')
plt.show()

"""Observe above model is not much better than default model

Still its fine not that bad. Atleast now tree is not much complex to understand

### ðŸŒ³ Decision Tree Pruning

In this section, we apply **Cost Complexity Pruning**, a post-training technique that trims branches of the decision tree that provide minimal predictive power.

**Why prune?**
- To reduce overfitting by eliminating branches that may capture noise in the training data.
- To simplify the model and improve generalization to unseen data.

**How it works:**
- The pruning path is generated using cost_complexity_pruning_path(), which provides a list of effective alpha values (ccp_alphas) and corresponding impurities.
- Each alpha represents a different level of pruning â€” higher alphas yield simpler trees.
- We loop through these alphas to train and evaluate multiple pruned trees.

**Key steps:**
- Plot training vs test accuracy across different alpha values.
- Identify the alpha that balances simplicity with accuracy.
- Visualize the final pruned tree for interpretability.

This method provides an elegant and data-driven way to improve model robustness while keeping complexity under control.
"""

model_dt

pruning_path = model_dt.cost_complexity_pruning_path(X_train,y_train)

alphas, impurities = pruning_path.ccp_alphas,pruning_path.impurities

alphas

impurities

train_accuracy, test_accuracy = [],[]

for ccp_alpha in alphas:
    dt_clf = DecisionTreeClassifier(ccp_alpha=ccp_alpha,random_state=108)
    dt_clf.fit(X_train,y_train)

    y_pred_train= dt_clf.predict(X_train)
    y_pred_test= dt_clf.predict(X_test)

    train_accu = metrics.accuracy_score(y_pred_train,y_train)
    train_accuracy.append(train_accu)

    test_accu = metrics.accuracy_score(y_pred_test,y_test)
    test_accuracy.append(test_accu)

plt.figure(figsize=(16,6))

plt.plot(alphas,train_accuracy,label='train',marker='o',linestyle='dashed')
plt.plot(alphas,test_accuracy,label='test',marker='o',linestyle='dashed')

plt.legend(loc="best",prop={'size':10})
plt.xlabel('alpha',size=15)
plt.ylabel('accuracy',size=15)

plt.show()

final_dt_clf = DecisionTreeClassifier(ccp_alpha=0.01,random_state=108)

final_model = final_dt_clf.fit(X_train,y_train)

y_pred_train = final_model.predict(X_train)

y_pred_test = final_model.predict(X_test)

final_train_accuracy = metrics.accuracy_score(y_pred_train,y_train)
final_test_accuracy = metrics.accuracy_score(y_pred_test,y_test)

print(f' Final_train_accuracy\n {final_train_accuracy}','\n','***'*6)
print(f' Final_test_accuracy\n {final_test_accuracy}')

plt.figure(figsize=(25,10))

plot_tree(final_model,filled=True)

plt.show()

print(export_text(model_dt))

"""## Next Steps

This project was designed to showcase my practical decision tree modeling skills within a healthcare-inspired context. However, there are several areas that could enhance both performance and complexity management in future iterations:

- **Ensemble Methods:** Incorporate Random Forest or Gradient Boosting to improve classification robustness and reduce variance.
- **Feature Engineering:** Explore polynomial or interaction terms and domain-specific feature grouping to improve model learning.
- **Model Explainability:** Use tools like SHAP or LIME to provide interpretable insights for non-technical healthcare stakeholders.
- **Model Deployment:** Package the model into an API using Flask or FastAPI to simulate integration with clinical decision-support tools.
- **Larger Dataset Application:** Apply this workflow to real-world EMR data or larger pharmacological datasets for higher fidelity modeling.

These steps would extend the current proof-of-concept into a scalable, production-ready classification tool.

"""