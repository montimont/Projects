# -*- coding: utf-8 -*-
"""Dataset_Uni_MultiVariate_Setup.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/186nF2zJWaYAgGWp7IWFmDHq6LWW-ahVx
"""

import pandas as pd

data = pd.read_csv(r'/content/drive/MyDrive/Colab Notebooks/Scorecard_Project/loan_data.csv')

"""# datasetForUnivariateVSExceptIV"""

import pandas as pd
import numpy as np

import matplotlib.pyplot as plt

pd.set_option('display.max_columns', None)

def calculate_woe_iv(dataset, feature, target):
    lst = []
    for i in range(dataset[feature].nunique()):
        val = list(dataset[feature].unique())[i]
        lst.append({
            'Value': val,
            'All': dataset[dataset[feature] == val].count()[feature],
            'Good': dataset[(dataset[feature] == val) & (dataset[target] == 0)].count()[feature],
            'Bad': dataset[(dataset[feature] == val) & (dataset[target] == 1)].count()[feature]
        })

    dset = pd.DataFrame(lst)
    dset['Distr_Good'] = (dset['Good'] + 0.5) / dset['Good'].sum()
    dset['Distr_Bad'] = (dset['Bad'] + 0.5) / dset['Bad'].sum()
    dset['WoE'] = np.log(dset['Distr_Good']/ dset['Distr_Bad'])
    dset['IV'] = (dset['Distr_Good'] - dset['Distr_Bad']) * dset['WoE']
    iv = dset['IV'].sum()

    dset = dset.sort_values(by='WoE')

    return dset[['Value', 'All', 'Good', 'Bad', 'WoE']], iv

lstvar = ['person_education',
 'person_income',
 'person_emp_exp',
 'person_home_ownership',
 'loan_amnt',
 'loan_intent',
 'loan_int_rate',
 'loan_percent_income',
 'cb_person_cred_hist_length',
 'credit_score',
 'previous_loan_defaults_on_file',
 'loan_status']

combined = data[lstvar]

combined.head()

dataFiltered = combined

dataToAnalyze = dataFiltered

dataToAnalyze

dataToAnalyze = dataToAnalyze.fillna(-1)

dataToAnalyze.head()

dataToAnalyze.select_dtypes(include=['object'])

dictobject = dict(dataToAnalyze.select_dtypes(include=['object']).nunique())

dictobject

lstobject = [k for (k,v) in dictobject.items() if v < 50]

lstobject

lstToremove = [k for (k,v) in dictobject.items() if v >= 100]

lstToremove

dataToAnalyze.info()

dataToAnalyze = dataToAnalyze.drop(columns = lstToremove)

lstobject = list(dataToAnalyze.select_dtypes(include=['object']).columns)

IVs = []
woe_mappings = []
features = []

for i in lstobject:
    try:
        woe, iv = calculate_woe_iv(dataToAnalyze, i, 'loan_status')
        woe_map = dict(zip(woe['Value'], woe['WoE']))

        dataToAnalyze.loc[:, i] = dataToAnalyze[i].map(woe_map)

        # Only append if everything above succeeded
        features.append(i)
        IVs.append(iv)
        woe_mappings.append(woe_map)

    except Exception as e:
        print(f"[SKIPPED] {i} due to error: {e}")

results = pd.DataFrame({
    'features': features,
    'iv': IVs,
    'woe_mappings': woe_mappings
})

results

dataToAnalyze.info()

dataToAnalyze[lstobject] = dataToAnalyze[lstobject].astype('float64')

dataToAnalyze.info()

dataToAnalyze[lstobject]

dataToAnalyze[lstobject].nunique()

dataToAnalyze[lstobject].isna().sum()

dataToAnalyze[lstobject] = dataToAnalyze[lstobject].apply(lambda x: x*100)

dataToAnalyze[lstobject]

dataToAnalyze.to_csv('Internal_test_0_datasetForUnivariateVSExceptIV.csv')

results.to_csv('Internal_test_0_univariateVS_woe_mappings_iv.csv')

"""# datasetForMultivariateVSExceptIV"""

def calculate_woe_iv(dataset, feature, target):
    lst = []
    for i in range(dataset[feature].nunique()):
        val = list(dataset[feature].unique())[i]
        lst.append({
            'Value': val,
            'All': dataset[dataset[feature] == val].count()[feature],
            'Good': dataset[(dataset[feature] == val) & (dataset[target] == 0)].count()[feature],
            'Bad': dataset[(dataset[feature] == val) & (dataset[target] == 1)].count()[feature]
        })

    dset = pd.DataFrame(lst)
    dset['Distr_Good'] = (dset['Good'] + 0.5) / dset['Good'].sum()
    dset['Distr_Bad'] = (dset['Bad'] + 0.5) / dset['Bad'].sum()
    dset['WoE'] = np.log(dset['Distr_Good']/ dset['Distr_Bad'])
    dset['IV'] = (dset['Distr_Good'] - dset['Distr_Bad']) * dset['WoE']
    iv = dset['IV'].sum()

    dset = dset.sort_values(by='WoE')

    return dset[['Value', 'All', 'Good', 'Bad', 'WoE']], iv

lstvar = ['person_education',
 'person_income',
 'person_emp_exp',
 'person_home_ownership',
 'loan_amnt',
 'loan_intent',
 'loan_int_rate',
 'loan_percent_income',
 'cb_person_cred_hist_length',
 'credit_score',
 'previous_loan_defaults_on_file',
 'loan_status']

combined = data[lstvar]

combined.head()

dataFiltered = combined

dataToAnalyze = dataFiltered.iloc[:, :]

dataToAnalyze

dataToAnalyze = dataToAnalyze.fillna(-1)

dataToAnalyze.head()

dataToAnalyze.select_dtypes(include=['object'])

dictobject = dict(dataToAnalyze.select_dtypes(include=['object']).nunique())

dictobject

lstobject = [k for (k,v) in dictobject.items() if v < 50]

lstobject

lstToremove = [k for (k,v) in dictobject.items() if v >= 100]

lstToremove

lstobject

dataToAnalyze.info()

dataToAnalyze = dataToAnalyze.drop(columns = lstToremove)

lstobject = list(dataToAnalyze.select_dtypes(include=['object']).columns)

lstobject

IVs = []
woe_mappings = []
features = []

for i in lstobject:
    try:
        woe, iv = calculate_woe_iv(dataToAnalyze, i, 'loan_status')
        woe_map = dict(zip(woe['Value'], woe['WoE']))

        dataToAnalyze.loc[:, i] = dataToAnalyze[i].map(woe_map)

        # Only append if everything above succeeded
        features.append(i)
        IVs.append(iv)
        woe_mappings.append(woe_map)

    except Exception as e:
        print(f"[SKIPPED] {i} due to error: {e}")

results = pd.DataFrame({
    'features': features,
    'iv': IVs,
    'woe_mappings': woe_mappings
})

results

dataToAnalyze[lstobject] = dataToAnalyze[lstobject].astype('float64')

dataToAnalyze[lstobject]

dataToAnalyze[lstobject].nunique()

dataToAnalyze[lstobject].isna().sum()

dataToAnalyze[lstobject] = dataToAnalyze[lstobject].apply(lambda x: x*100)

dataToAnalyze[lstobject]

dataToAnalyze.to_csv('Internal_test_0_datasetForMultivariateVSExceptIV.csv')

results.to_csv('Internal_test_0_multivariateVS_woe_mappings_iv.csv')